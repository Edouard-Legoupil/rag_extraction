<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Edouard Legoupil, UNHCR Evaluation Office">
<meta name="dcterms.date" content="2024-05-10">

<title>Generating and Improving Evaluation Report “Brief”</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="index_files/libs/clipboard/clipboard.min.js"></script>
<script src="index_files/libs/quarto-html/quarto.js"></script>
<script src="index_files/libs/quarto-html/popper.min.js"></script>
<script src="index_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="index_files/libs/quarto-html/anchor.min.js"></script>
<link href="index_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="index_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="index_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="index_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="index_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<style>html{ scroll-behavior: smooth; }</style>
<link rel="shortcut icon" href="data:image/svg+xml;base64,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">


</head>

<body>

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#abstract" id="toc-abstract" class="nav-link active" data-scroll-target="#abstract">Abstract</a></li>
  <li><a href="#introduction" id="toc-introduction" class="nav-link" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#environment-set-up" id="toc-environment-set-up" class="nav-link" data-scroll-target="#environment-set-up">Environment Set up</a></li>
  <li><a href="#information-retrieval" id="toc-information-retrieval" class="nav-link" data-scroll-target="#information-retrieval">Information Retrieval</a>
  <ul class="collapse">
  <li><a href="#load-the-pdf" id="toc-load-the-pdf" class="nav-link" data-scroll-target="#load-the-pdf">Load the PDF</a></li>
  <li><a href="#chunking" id="toc-chunking" class="nav-link" data-scroll-target="#chunking">Chunking</a></li>
  <li><a href="#instantiate-a-vector-database" id="toc-instantiate-a-vector-database" class="nav-link" data-scroll-target="#instantiate-a-vector-database">Instantiate a Vector Database</a></li>
  <li><a href="#generate-embedding" id="toc-generate-embedding" class="nav-link" data-scroll-target="#generate-embedding">Generate Embedding</a></li>
  <li><a href="#get-from-persistent-storage" id="toc-get-from-persistent-storage" class="nav-link" data-scroll-target="#get-from-persistent-storage">Get from persistent storage</a></li>
  </ul></li>
  <li><a href="#content-generation" id="toc-content-generation" class="nav-link" data-scroll-target="#content-generation">Content Generation</a>
  <ul class="collapse">
  <li><a href="#set-up-a-local-llm" id="toc-set-up-a-local-llm" class="nav-link" data-scroll-target="#set-up-a-local-llm">Set up a local LLM</a></li>
  <li><a href="#summarisation-prompt" id="toc-summarisation-prompt" class="nav-link" data-scroll-target="#summarisation-prompt">Summarisation Prompt</a></li>
  <li><a href="#set-up-the-retriever" id="toc-set-up-the-retriever" class="nav-link" data-scroll-target="#set-up-the-retriever">Set up the Retriever</a></li>
  <li><a href="#build-the-chain" id="toc-build-the-chain" class="nav-link" data-scroll-target="#build-the-chain">Build the Chain</a></li>
  <li><a href="#save-in-a-word-document" id="toc-save-in-a-word-document" class="nav-link" data-scroll-target="#save-in-a-word-document">Save in a word document</a></li>
  </ul></li>
  <li><a href="#process-evaluation" id="toc-process-evaluation" class="nav-link" data-scroll-target="#process-evaluation">Process Evaluation</a>
  <ul class="collapse">
  <li><a href="#build-an-alternate-brief" id="toc-build-an-alternate-brief" class="nav-link" data-scroll-target="#build-an-alternate-brief">Build an alternate “Brief”</a></li>
  <li><a href="#building-the-evaluation-dataset" id="toc-building-the-evaluation-dataset" class="nav-link" data-scroll-target="#building-the-evaluation-dataset">Building the evaluation dataset</a></li>
  <li><a href="#metrics-measurement" id="toc-metrics-measurement" class="nav-link" data-scroll-target="#metrics-measurement">Metrics Measurement</a></li>
  </ul></li>
  <li><a href="#ai-deployment" id="toc-ai-deployment" class="nav-link" data-scroll-target="#ai-deployment">AI Deployment</a>
  <ul class="collapse">
  <li><a href="#buy-or-build" id="toc-buy-or-build" class="nav-link" data-scroll-target="#buy-or-build">Buy or Build?</a></li>
  <li><a href="#ai-ready-data-human-review" id="toc-ai-ready-data-human-review" class="nav-link" data-scroll-target="#ai-ready-data-human-review">AI ready data &amp; Human Review</a></li>
  <li><a href="#fine-tuning" id="toc-fine-tuning" class="nav-link" data-scroll-target="#fine-tuning">Fine-Tuning</a></li>
  </ul></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">Conclusion</a></li>
  </ul>
</nav>
</div>
<main class="content page-columns page-full" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Generating and Improving Evaluation Report “<strong>Brief</strong>”</h1>
<p class="subtitle lead">Evaluating Retrieval-Augmented Generation with Large Language Model</p>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Edouard Legoupil, UNHCR Evaluation Office </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">10 May 2024</p>
    </div>
  </div>
  
    
  </div>
  

</header>

<div class="bg-primary text-white p-3 column-page">
<p><em>“We are drowning in information, while starving for wisdom. The world henceforth will be run by synthesizers, people able to put together the right information at the right time, think critically about it, and make important choices wisely.”</em> - E. O. Wilson</p>
</div>
<section id="abstract" class="level2">
<h2 class="anchored" data-anchor-id="abstract">Abstract</h2>
<p>Artificial Inteligence (AI) is presented as the potential trigger for the <a href="https://www.nature.com/articles/s41599-019-0253-6">fifth wave</a> of the <strong>evidence revolution</strong> (<em>following the 4 previous ones: 1.Outcome Monitoring, 2.Impact Evaluation, 3.Systematic Reviews and 4.Knowledge Brokering</em>). This actually reflects a situation where considering the <a href="https://www.uneval.org/evaluation/reports">numbers of published evaluation reports across the UN system</a>, <strong>information retrieval and evidence generalization</strong> challenges have arisen: How to extract the most relevant findings and recommendations from within a specific context and to reuse and re-inject them in a different but appropriate context?</p>
<p>The key deliverable from an evaluation process is usually a long report (<em>often over 60 pages PDF file</em>). From this report, two-pagers executive “briefs” are usually designed for the consumption of the senior executive audience. Striking the balance between concise and informative can be tricky but what remains more challenging is the subjective dimensions involved in <strong>choosing what to include and what to exclude</strong>, especially in terms of highlighting critical aspects while deciding on what are the less relevant details to omit… The potential fear of being, like Cassandra, the bearer of bad news comes with the structural risk of “cushioning” the real evaluation findings to a point where they get hidden. Relying on automated retrieval can therefore help improving the objectivity of the summarization.</p>
<p>Retrieval-augmented generation (RAG) is a type of Artificial Inteligence (AI) question-answering framework that <a href="https://arxiv.org/pdf/2005.11401">surfaced in 2020</a> and that synergizes the capabilities of Large Language Model (LLMs) and information retrieval systems, also called text mining. This paper is presenting the challenges and opportunities associated with those new approaches. It targets a technical audience that may consider including such techniques within their personal information management toolkit, and this working safely, fully offline on their own computer.</p>
<p>First, we explain how to create an initial <a href="https://github.com/Edouard-Legoupil/rag_extraction/raw/main/generated/Evaluation_Brief_response_text_bert.docx">two-pagers evaluation brief</a> using an orchestration of models and functions. Rather than relying on ad-hoc user interactions through a black box chat interface, it is possible to set up documented and <strong>reproducible</strong> scripts that can directly output a word document. The same approach could actually be applied to other textual analysis needs, for instance: extracting causal chains from the transcriptions of Focus Group Discussions, generating potential theories of change from needs assessment reports or assessing sufficient usage of programmatic evidences when developing Operation Strategic Plan.</p>
<p>Second, we review the techniques that can be used to <strong>evaluate</strong> and optimize summarisation scripts to minimize the risk of AI hallucinations. We generate a <a href="https://github.com/Edouard-Legoupil/rag_extraction/raw/main/generated/Evaluation_Brief_response_mmr_recursivecharactertext_bge.docx">second alternative brief</a>, and then create an evaluation dataset to explore the different metrics that can be used to evaluate information retrieval process.</p>
<p>Last we discuss how such approach can actually inform decisions and strategies on future AI <strong>deployment</strong> approaches: i.e.&nbsp;what needs to be set up to create training dataset that would allow to fine-tune models and further increase the performance of evidence retrieval and re-injection.</p>
</section>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>Building a robust information retrieval system requires to configure different components:</p>
<ol type="1">
<li><p><strong>Retrieval</strong>: Build a knowledge base and configure how to retrieve the information from it;</p></li>
<li><p><strong>Generation</strong>: Define efficient prompt to query the system;</p></li>
<li><p><strong>Evaluation</strong>: Explore and combine various options for both Retrieval and Generation to compare the results.</p></li>
<li><p><strong>Deployment</strong>: Organise AI-ready feedback and prepare data for fine-tuning.</p></li>
</ol>
<p>This paper compiles the results of experimentation applied to a practical use case. It includes a <em>cookbook</em> with a reproducible recipes so that colleagues can rerun and learn from it. It also contains broader considerations on the usage of AI for public programme evaluations, especially in the last part around deployment. We used here the <a href="https://www.unhcr.org/sites/default/files/legacy-pdf/5dd4f7d24.pdf">2019 Evaluation of UNHCR’s data use and information management approaches</a> to illustrate the process. We hope that eaders will be able to adjust this tutorial to their own use cases! Script below re based on <a href="https://python.langchain.com/v0.1/docs/use_cases/question_answering/">langChain</a> python library but the same pipeline could also be built with the other main LLM orchestration library called <a href="https://docs.llamaindex.ai/en/stable/use_cases/q_and_a/">LlamaIndex</a></p>
<p>The illustration from <a href="https://huggingface.co/learn/cookbook/en/rag_evaluation">HuggingFace RAG Evaluation</a> below nicely visualize the first two elements of the system architecture: retrieval (that includes: chunking, embedding, storing and retrieving) and generation (that includes prompting an LLM).</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="RAG_workflow.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">RAG Evaluation, https://huggingface.co/learn/cookbook/en/rag_evaluation</figcaption>
</figure>
</div>
</section>
<section id="environment-set-up" class="level2">
<h2 class="anchored" data-anchor-id="environment-set-up">Environment Set up</h2>
<p>Make sure to install the last version of python and create a dedicated python environment to have a fresh install where to manage correctly all the dependencies between packages. This can be done with <a href="https://docs.conda.io/en/latest/">conda</a> python modules management utility.</p>
<p>First directly in your OS Shell, create a new environment - here called <strong><code>evalenv</code></strong></p>
<blockquote class="blockquote">
<p>conda create –name evalenv python=3.11</p>
</blockquote>
<p>Then activate it! Et voila!</p>
<blockquote class="blockquote">
<p>conda activate evalenv</p>
</blockquote>
<p>Once this environment selected as a kernel to run the notebook, we can install the required python libraries for RAG:</p>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co">## Library to load the PDF</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>pip install <span class="op">--</span>upgrade <span class="op">--</span>quiet install pypdf</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="co">## Library for chunking</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>pip install <span class="op">--</span>upgrade <span class="op">--</span>quiet  tiktoken</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>pip install <span class="op">--</span>upgrade <span class="op">--</span>quiet nltk</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="co">## Library for the embedding</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>pip install <span class="op">--</span>upgrade <span class="op">--</span>quiet  gpt4all</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>pip install <span class="op">--</span>upgrade <span class="op">--</span>quiet  sentence<span class="op">-</span>transformers</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="co">## Library to store the embeddng in a vector DB</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>pip install <span class="op">--</span>upgrade <span class="op">--</span>quiet  chromadb</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="co">## Library for the LLM interaction</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>pip install <span class="op">--</span>upgrade <span class="op">--</span>quiet install langchain</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>pip install <span class="op">--</span>upgrade <span class="op">--</span>quiet langchain<span class="op">-</span>community</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="co">## Library to save the results in a word document</span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>pip install <span class="op">--</span>upgrade <span class="op">--</span>quiet python<span class="op">-</span>docx </span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a><span class="co">## Library to evaluat the RAG process</span></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>pip install <span class="op">--</span>upgrade <span class="op">--</span>quiet ragas  </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Note: you may need to restart the kernel to use updated packages.
Note: you may need to restart the kernel to use updated packages.
Note: you may need to restart the kernel to use updated packages.
Note: you may need to restart the kernel to use updated packages.
Note: you may need to restart the kernel to use updated packages.
Note: you may need to restart the kernel to use updated packages.
Note: you may need to restart the kernel to use updated packages.
Note: you may need to restart the kernel to use updated packages.
Note: you may need to restart the kernel to use updated packages.
Note: you may need to restart the kernel to use updated packages.</code></pre>
</div>
</div>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># then Restart the jupyter kernel for this notebook</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>reset <span class="op">-</span>f</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="information-retrieval" class="level2">
<h2 class="anchored" data-anchor-id="information-retrieval">Information Retrieval</h2>
<section id="load-the-pdf" class="level3">
<h3 class="anchored" data-anchor-id="load-the-pdf">Load the PDF</h3>
<p>There plenty of potential python packages to load pdf files… More details <a href="https://python.langchain.com/docs/modules/data_connection/document_loaders/pdf">here</a>. Note that more loader also exist for other type of data!!!</p>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain_community.document_loaders <span class="im">import</span> PyPDFLoader</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>loader <span class="op">=</span> PyPDFLoader(<span class="st">"files/Info_Mngt_eval_2019.pdf"</span>)</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>docs <span class="op">=</span> loader.load_and_split()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="chunking" class="level3">
<h3 class="anchored" data-anchor-id="chunking">Chunking</h3>
<p>If you have a large document, because of memory management, you will not be able to process it in one chunk. LangChain offers several built-in text splitters to <strong>divide text into smaller chunks</strong> based on different criteria.</p>
<p>Example of options that can be tested are:</p>
<ul>
<li><p>Simple character-level processing with <code>CharacterTextSplitter,</code></p></li>
<li><p>Recursive Splitting with <code>RecursiveCharacterTextSplitter</code>,</p></li>
<li><p>Words or semantic units with <code>TokenTextSplitter</code>,</p></li>
<li><p>Context-aware splitting with <code>NLTKTextSplitter</code> .</p></li>
</ul>
<p>See example to understand how chunking works, see this online <a href="https://huggingface.co/spaces/m-ric/chunk_visualizer">viz</a>.</p>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain.text_splitter <span class="im">import</span> CharacterTextSplitter</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>splitter_text <span class="op">=</span> CharacterTextSplitter(chunk_size<span class="op">=</span><span class="dv">1000</span>, chunk_overlap<span class="op">=</span><span class="dv">200</span>)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>chunks_text <span class="op">=</span> splitter_text.split_documents(docs)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain.text_splitter <span class="im">import</span> RecursiveCharacterTextSplitter </span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>splitter_recursivecharactertext <span class="op">=</span> RecursiveCharacterTextSplitter(chunk_size<span class="op">=</span><span class="dv">1000</span>, chunk_overlap<span class="op">=</span><span class="dv">200</span>)</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>chunks_recursivecharactertext <span class="op">=</span> splitter_recursivecharactertext.split_documents(docs)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain.text_splitter <span class="im">import</span> TokenTextSplitter</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>splitter_tokentext <span class="op">=</span> TokenTextSplitter(chunk_size<span class="op">=</span><span class="dv">1000</span>, chunk_overlap<span class="op">=</span><span class="dv">200</span>)</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>chunks_tokentext <span class="op">=</span> splitter_tokentext.split_documents(docs)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain_text_splitters <span class="im">import</span> NLTKTextSplitter</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>splitter_nltktext <span class="op">=</span> NLTKTextSplitter(chunk_size<span class="op">=</span><span class="dv">1000</span>)</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>chunks_nltktext <span class="op">=</span> splitter_nltktext.split_documents(docs)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="instantiate-a-vector-database" class="level3">
<h3 class="anchored" data-anchor-id="instantiate-a-vector-database">Instantiate a Vector Database</h3>
<p>A <a href="https://python.langchain.com/docs/modules/data_connection/vectorstores/">vector database</a> is a database that allows to efficiently store and query embeddings. Embedding are actually a <strong>numeric representation of text data</strong>. This conversion from text to numeric is used to represent words, sentences, or even entire documents in a compact and meaningful way. It captures the essence of a word’s meaning, context, and relationships with other words.</p>
<p>Vector databases extend the capabilities of traditional relational databases to embedding. However, the key distinguishing feature of a vector database is that query results aren’t an exact match to the query. Instead, using a specified <strong>similarity metric</strong>, the vector database returns data that are similar to a query.</p>
<p>There are here again numerous options in terms of Open Source vector DB that can be used - for instance: <a href="https://www.trychroma.com/">ChromaDB</a>, <a href="https://qdrant.tech/">Qdrant</a>, <a href="https://milvus.io/">Milvus</a> or <a href="https://engineering.fb.com/2017/03/29/data-infrastructure/faiss-a-library-for-efficient-similarity-search/">FAISS</a>. Here we will just use Chroma.</p>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain_community.vectorstores <span class="im">import</span> Chroma</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> chromadb </span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>chroma_client <span class="op">=</span> chromadb.PersistentClient(path<span class="op">=</span><span class="st">"persist/"</span>)</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="co">## A collection is created with the following</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a><span class="co">#chroma_collection = chroma_client.create_collection('collection')</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="generate-embedding" class="level3">
<h3 class="anchored" data-anchor-id="generate-embedding">Generate Embedding</h3>
<p>To generate embedding, we need a dedicated model and there’s no single “best” option. Words with similar contexts tend to have closer vector representations. Some static word embeddings models are good capturing basic semantic relationships and are computationally efficient and fast but might not capture complex semantics or context-dependent meanings. Contextual Embeddings models have been developped to capture word meaning based on context, considering surrounding words in a sentence and handling ambiguity. But Training and usage can be computationally expensive, model sizes can be large.</p>
<p>LangChain often integrates with libraries like <a href="https://huggingface.co/sentence-transformers">Hugging Face Transformers</a> for embedding usage. Best is to experiment with different embeddings to see what works best for a specific use case and dataset. There are plenty of options also depending on the languages.</p>
<p>Here we start with testing with <a href="https://python.langchain.com/v0.1/docs/integrations/text_embedding/gpt4all/">GPT4ALL</a></p>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain_community.embeddings <span class="im">import</span> GPT4AllEmbeddings </span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>embeddings_bert <span class="op">=</span> GPT4AllEmbeddings()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now we can store the embeddings and associated metadata in the <code>chroma vector</code> database using a specific collection name. Below we create distinct stores for each chunking options.</p>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>vectorstore_text_bert <span class="op">=</span> Chroma.from_documents(</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>    documents<span class="op">=</span>chunks_text, </span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>    embedding<span class="op">=</span>embeddings_bert, </span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>    collection_name<span class="op">=</span> <span class="st">"text_bert"</span>,</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>    persist_directory <span class="op">=</span> <span class="st">"persist"</span>)</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>vectorstore_text_bert.persist()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/edouard/.pyenv/versions/3.11.6/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.
  warn_deprecated(</code></pre>
</div>
</div>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>vectorstore_recursivecharactertext_bert <span class="op">=</span> Chroma.from_documents(</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>    documents<span class="op">=</span>chunks_recursivecharactertext,</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>    embedding<span class="op">=</span>embeddings_bert,</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>    collection_name<span class="op">=</span> <span class="st">"recursivecharactertext_bert"</span>,</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>    persist_directory <span class="op">=</span> <span class="st">"persist"</span>)</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>vectorstore_recursivecharactertext_bert.persist()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>vectorstore_tokentext_bert <span class="op">=</span> Chroma.from_documents(</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>    documents<span class="op">=</span>chunks_tokentext, </span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>    embedding<span class="op">=</span>embeddings_bert, </span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>    collection_name<span class="op">=</span> <span class="st">"tokentext_bert"</span>,</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>    persist_directory <span class="op">=</span> <span class="st">"persist"</span>)</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>vectorstore_tokentext_bert.persist()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>vectorstore_nltktext_bert <span class="op">=</span> Chroma.from_documents(</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>    documents<span class="op">=</span>chunks_nltktext, </span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>    embedding<span class="op">=</span>embeddings_bert, </span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>    collection_name<span class="op">=</span> <span class="st">"nltktext_bert"</span>,</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>    persist_directory <span class="op">=</span> <span class="st">"persist"</span>)</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>vectorstore_nltktext_bert.persist()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="get-from-persistent-storage" class="level3">
<h3 class="anchored" data-anchor-id="get-from-persistent-storage">Get from persistent storage</h3>
<p>Chroma can run in various modes. Here we used the <code>persist</code> mode that allows to save to disk and load later. We can then re-open a previous database using its folder path:</p>
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> chromadb</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>client <span class="op">=</span> chromadb.PersistentClient(path<span class="op">=</span><span class="st">"persist/"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Then we can get the name of collection available within that database</p>
<div class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>collections <span class="op">=</span> client.list_collections()</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(collections)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[Collection(name=recursivecharactertext_bge), Collection(name=tokentext_bert), Collection(name=recursivecharactertext_bert), Collection(name=text_bge), Collection(name=langchain), Collection(name=text_bert), Collection(name=nltktext_bert)]</code></pre>
</div>
</div>
<p>and get a previously saved vector collection</p>
<div class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>vectorstore2_text_bert <span class="op">=</span> Chroma(collection_name<span class="op">=</span><span class="st">"text_bert"</span>,</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>                                persist_directory<span class="op">=</span><span class="st">"persist/"</span>, </span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>                                embedding_function<span class="op">=</span>embeddings_bert)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
<section id="content-generation" class="level2">
<h2 class="anchored" data-anchor-id="content-generation">Content Generation</h2>
<section id="set-up-a-local-llm" class="level3">
<h3 class="anchored" data-anchor-id="set-up-a-local-llm">Set up a local LLM</h3>
<p>If do not have access to a LLM API, an alternative is to install a local one and there are again plenty of Foundation LLM options to select from. Foundation models are AI neural networks trained on massive amounts of raw data (usually with unsupervised learning) that can be adapted to a wide variety of tasks.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Open-source Large Language Models (LLM) have multiple advantages:</p>
<ul>
<li><p><strong>Transparency and Flexibility</strong>: accessible to the public, allowing developers to inspect, modify, and distribute the code. This transparency fosters a community-driven development process, leading to rapid innovation and diverse applications.</p></li>
<li><p><strong>Cost Savings</strong>: generally more affordable in the long run as they don’t involve licensing fees, once infrastructure is setup and/or can be used offline on local computer.</p></li>
<li><p><strong>Added Features and Community Contributions</strong>: can leverage multiple providers and internal teams for updates and support, which enables to stay at the forefront of technology and exercise greater control over their usage.</p></li>
<li><p><strong>Customizability</strong>: allow for added features and benefit from community contributions. They are ideal for projects that require customization and those where budget constraints are a primary concern.</p></li>
<li><p><strong>Data Protection</strong>: allow to use within the data enclave of your own computer without any data being sent to a remote server.</p></li>
</ul>
</div>
</div>
<p>There are multiple options to do that. An easy one is to install <a href="https://ollama.com/">OLLAMA</a>, which offers a wide <a href="https://ollama.com/library">variety of open models</a> from the “AI Race” competitors <a href="https://chat.lmsys.org/">arena</a>: <a href="https://ollama.com/library/llama3">LLama3</a> from Facebook, <a href="https://ollama.com/library/gemma">gemma</a> from Google, <a href="https://ollama.com/library/phi3">phi3</a> Microsoft but also <a href="https://ollama.com/library/qwen">qwen</a> from the Chinese AliBaba, <a href="https://ollama.com/library/falcon">falcon</a> from the Emirati Technology Innovation Institute, or <a href="https://ollama.com/library/mixtral">Mixtral</a> from the french startup Mistral_AI. Langchain as dedicated <a href="https://python.langchain.com/docs/integrations/chat/ollama">module to work with ollama</a>.</p>
<p>Below, we start with <a href="https://mistral.ai/news/mixtral-of-experts/">Mixtral Sparse Mixture-of-Expert</a>, and specifically the quantized version: <a href="https://huggingface.co/TheBloke/Mixtral-8x7B-Instruct-v0.1-GGUF#explanation-of-quantisation-methods">8x7b-instruct-v0.1-q4_K_M</a>, an open-weight model designed to optimize performance-to-cost ratio, aka small in size to run on a strong laptop but good in performance. This download a file with the model which size around 26Gb.</p>
<div class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain_community.chat_models <span class="im">import</span> ChatOllama</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>llm_ollama <span class="op">=</span> ChatOllama(</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>    model<span class="op">=</span><span class="st">"mixtral:8x7b-instruct-v0.1-q4_K_M"</span>,  </span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>    temperature<span class="op">=</span><span class="fl">0.2</span>, </span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>    request_timeout<span class="op">=</span><span class="dv">500</span></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The temperature is setting the <em>creativeness</em> of the response - the higher the more creative - below we will remain conservative! It is the equivalent of the <em>conversation style</em> setting in copilot: <em>creative [1-0.7], balanced ]0.7-0.4], precise ]0.4,0]</em>…</p>
</section>
<section id="summarisation-prompt" class="level3">
<h3 class="anchored" data-anchor-id="summarisation-prompt">Summarisation Prompt</h3>
<p>A prompt is is a piece of text or a set of instructions, used by the LLM to generate a response or perform a task. Writing a good summarization prompt involves a few key steps:</p>
<ul>
<li><p>Be <strong>Specific</strong>: Clearly state what you want to summarize. For example, “Summarize this Operation Strategic Plan in 200 words using abstractive summarization” or “Provide a summary of this needs assessment report, highlighting its key takeaways”.</p></li>
<li><p>Define the <strong>Scope</strong>: Specify the length or depth of the summary you need. For instance, “Summarize this text into two paragraphs with simple language to make it easier to understand” or “Create a summary of this report by summarizing all chapters separately and then generating an overall summary of the report”.</p></li>
<li><p>Set the <strong>Context</strong>: If the summary is for a specific purpose or audience, mention it in the prompt. For example, “I need to write talking points based on this report. Help me summarize this text for better understanding so that I can use it as an introduction emai” or “Summarize this for me like I’m 8 years old”.</p></li>
<li><p>Use <strong>Clear and Concise</strong> Language: Avoid unnecessary complexity or ambiguity. A good prompt should provide enough direction to start but leave room for creativity.</p></li>
</ul>
<p>Here we will try to create a prompt that generate an “Evaluation Brief” from the larger evaluation report.</p>
<p>Mixtral comes with specific tags to use for the prompt:</p>
<p><code>&lt;s&gt;\[INST\] Instruction \[/INST\] Model answer&lt;/s&gt;\[INST\] Follow-up instruction \[/INST\]</code></p>
<div class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>RAG_prompt <span class="op">=</span> <span class="st">"""</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="st">&lt;s&gt; </span></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a><span class="st">[INST]Act if you were a public program evaluation specialist. </span></span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a><span class="st">Your audience target is composed of Senior Executives that are managing the operation or program that got evaluated.[/INST]</span></span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a><span class="st">Your task is to generate an executive summary of the report you just ingested. &lt;/s&gt;</span></span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a><span class="st">[INST]</span></span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a><span class="st">The summary should follow the following defined structure:</span></span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a><span class="st"> </span></span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a><span class="st"> - In the first part titled "What have we learn?", start with a description of the Forcibly Displaced population in the operation and include as 5 bullet points, the main challenges in relation with the evaluation objectives that have been identified in the document. </span></span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a><span class="st"> For each challenge explain why it's a problem and give a practical example to illustrate the consequence of this problem.</span></span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a><span class="st"> </span></span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a><span class="st"> - In a second part titled: "How did we get there?" try to review the common root causes for all the challenges that have been identified.  </span></span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a><span class="st"> </span></span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a><span class="st"> - In a third part, title: "What is working well?", provide a summary of the main success and achievement, i.e. things that have been identified as good practices and / or effective by the evaluators.</span></span>
<span id="cb21-18"><a href="#cb21-18" aria-hidden="true" tabindex="-1"></a><span class="st"> </span></span>
<span id="cb21-19"><a href="#cb21-19" aria-hidden="true" tabindex="-1"></a><span class="st"> - In the fourth part: "Now What to do?", include and summarize the recommendations proposed by the evaluation. Classify the recommendations according to their relevant level:</span></span>
<span id="cb21-20"><a href="#cb21-20" aria-hidden="true" tabindex="-1"></a><span class="st">      </span></span>
<span id="cb21-21"><a href="#cb21-21" aria-hidden="true" tabindex="-1"></a><span class="st">      1. "Operational Level": i.e recommendations that need to be implemented in the field as an adaptation or change of current practices. Please flag clearly, if this is the case, the recommendations related to practice that should be stopped or discontinued;</span></span>
<span id="cb21-22"><a href="#cb21-22" aria-hidden="true" tabindex="-1"></a><span class="st">       </span></span>
<span id="cb21-23"><a href="#cb21-23" aria-hidden="true" tabindex="-1"></a><span class="st">      2. "Organizational level": i.e recommendations that require changes in staffing or capacity building. Please flag clearly, if this is the case, the recommendations related to practice that should be stopped or discontinued;</span></span>
<span id="cb21-24"><a href="#cb21-24" aria-hidden="true" tabindex="-1"></a><span class="st">    </span></span>
<span id="cb21-25"><a href="#cb21-25" aria-hidden="true" tabindex="-1"></a><span class="st">      3. "Strategic Level": i.e recommendations that require a change in existing policy and rules.</span></span>
<span id="cb21-26"><a href="#cb21-26" aria-hidden="true" tabindex="-1"></a><span class="st"> </span></span>
<span id="cb21-27"><a href="#cb21-27" aria-hidden="true" tabindex="-1"></a><span class="st"> - At the end, for the "Conclusion", craft a reflective conclusion in one sentence that highlights the broader significance of the discussed topic. </span></span>
<span id="cb21-28"><a href="#cb21-28" aria-hidden="true" tabindex="-1"></a><span class="st">[/INST]</span></span>
<span id="cb21-29"><a href="#cb21-29" aria-hidden="true" tabindex="-1"></a><span class="st">"""</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="set-up-the-retriever" class="level3">
<h3 class="anchored" data-anchor-id="set-up-the-retriever">Set up the Retriever</h3>
<p>A <a href="https://python.langchain.com/docs/modules/data_connection/retrievers/">retriever</a> acts as an information gatekeeper in the RAG architecture. Its primary function is to search through a large corpus of data to find relevant pieces of information that can be used for text generation. You can think of it as a specialized librarian who knows exactly which ‘books’ to pull off the ‘shelves’ when you ask a question. In other words, the retriever first fetches relevant parts of the document pertaining to the user query, and then the Large Language Model (LLM) uses this information to generate a response.</p>
<p>The search_type argument within <code>vectorstore.as_retriever</code> for LangChain allows you to specify the retrieval strategy used to find relevant documents in your vector store. Different options are available:</p>
<ol type="1">
<li><p>If you simply want the most relevant documents, “<strong>similarity</strong>” (default): This is the most common search type and is used by default. It performs a standard nearest neighbor search based on vector similarity. The retriever searches for documents in the vector store whose vector representations are closest to the query vector. Documents with higher similarity scores are considered more relevant and are returned first.</p></li>
<li><p>If you need diverse results that cover different aspects of a topic, “<strong>mmr</strong>” (Maximum Marginal Relevance): This search type focuses on retrieving documents that are both relevant to the query and diverse from each other. It aims to avoid redundancy in the results. MMR is particularly useful when you want a collection of documents that cover different aspects of a topic, rather than just multiple copies of the most similar document.</p></li>
<li><p>If you want to ensure a minimum level of relevance,“<strong>similarity_score_threshold</strong>”: This search type retrieves documents based on a similarity score threshold. It only returns documents that have a similarity score above the specified threshold. This allows you to filter out documents with low relevance to the query.</p></li>
</ol>
<p>The retriever also takes a series of potential parameters. The <code>search_kwargs={"k": 2,"score_threshold":0.8}</code> argument is a dictionary used to configure how documents are retrieved during the search process. This argument lets you control how many results you get (up to two in this case) and how good those results need to be (with a score of at least 0.8):</p>
<ul>
<li><p><strong>k</strong> (int): This parameter controls the number of documents to retrieve from the search. In this case, k: 2 specifies that the retriever should return up to two documents that match the search query.</p></li>
<li><p><strong>score_threshold</strong> (float): This parameter sets a minimum score threshold for retrieved documents. Documents with a score lower than 0.8 will be excluded from the results. This essentially acts as a quality filter, ensuring a certain level of relevance between the query and retrieved documents.</p></li>
</ul>
<p>The scoring mechanism used by the retriever might depend on the specific retriever implementation. It’s likely based on how well the retrieved documents match the search query. The effectiveness of these parameters depends on your specific use case and the quality of the underlying retrieval system.</p>
<p>Even with “similarity”, the retrieved documents might have varying degrees of relevance. Consider using ranking techniques within LangChain to further refine the results based on additional criteria. The underlying vector store might have limitations on the supported search types. Always refer to the documentation of your specific vector store to confirm available options.</p>
<p>We can build multiple retrievers out of the same <code>vectorstore</code>:</p>
<div class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>ragRetriever_text_bert <span class="op">=</span> vectorstore_text_bert.as_retriever()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>ragRetriever_recursivecharactertext_bert <span class="op">=</span> vectorstore_recursivecharactertext_bert.as_retriever()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>ragRetriever_similarity_tokentext_bert <span class="op">=</span> vectorstore_tokentext_bert.as_retriever(</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>            search_type<span class="op">=</span><span class="st">"similarity_score_threshold"</span>,</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>            search_kwargs<span class="op">=</span>{</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>                <span class="st">"k"</span>: <span class="dv">3</span>,</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>                <span class="st">"score_threshold"</span>: <span class="fl">0.4</span>,</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>            },</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>ragRetriever_similarity_nltktext_bert <span class="op">=</span> vectorstore_nltktext_bert.as_retriever(</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>            search_type<span class="op">=</span><span class="st">"similarity_score_threshold"</span>,</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>            search_kwargs<span class="op">=</span>{</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>                <span class="st">"k"</span>: <span class="dv">5</span>,</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>                <span class="st">"score_threshold"</span>: <span class="fl">0.8</span>,</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>            },</span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="build-the-chain" class="level3">
<h3 class="anchored" data-anchor-id="build-the-chain">Build the Chain</h3>
<p>A retrieval question-answer chain act as a pipe: it takes an incoming question, look up relevant documents using a retriever, then pass those documents along with the original question into an LLM and return the answer the original question.</p>
<p>Note that from this stage, the following steps may take time to run - this will be highly dependent on the power of your computer - obviously the availability of GPUs - Graphical Processing Unit - will significantly increase the speed! FYI, this notebook was built on a Thinkpad P53 with a Quadro T1000 GPU.</p>
<div class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain.chains <span class="im">import</span> RetrievalQA</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>qa_chain <span class="op">=</span> RetrievalQA.from_chain_type(</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>        llm<span class="op">=</span>llm_ollama,</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>        retriever<span class="op">=</span>ragRetriever_recursivecharactertext_bert, </span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>        chain_type<span class="op">=</span><span class="st">"stuff"</span>,</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>        return_source_documents<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a>response_text_bert <span class="op">=</span> qa_chain(RAG_prompt)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/edouard/.pyenv/versions/3.11.6/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.
  warn_deprecated(</code></pre>
</div>
</div>
</section>
<section id="save-in-a-word-document" class="level3">
<h3 class="anchored" data-anchor-id="save-in-a-word-document">Save in a word document</h3>
<p>To complete the process, let’s save the results within a a word document! This again can be automated</p>
<div class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> docx</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a document</span></span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>doc <span class="op">=</span> docx.Document()</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a><span class="co"># add a heading of level 0 (largest heading)</span></span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>doc.add_heading(<span class="st">'Evaluation Brief'</span>, <span class="dv">0</span>) </span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Add another paragraph</span></span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a>p <span class="op">=</span> doc.add_paragraph()</span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-12"><a href="#cb28-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Add a run with the summary and format it</span></span>
<span id="cb28-13"><a href="#cb28-13" aria-hidden="true" tabindex="-1"></a>run <span class="op">=</span> p.add_run(response_text_bert[<span class="st">"result"</span>])</span>
<span id="cb28-14"><a href="#cb28-14" aria-hidden="true" tabindex="-1"></a>run.font.name <span class="op">=</span> <span class="st">'Arial'</span></span>
<span id="cb28-15"><a href="#cb28-15" aria-hidden="true" tabindex="-1"></a>run.font.size <span class="op">=</span> docx.shared.Pt(<span class="dv">12</span>)</span>
<span id="cb28-16"><a href="#cb28-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-17"><a href="#cb28-17" aria-hidden="true" tabindex="-1"></a><span class="co">## Add  a disclaimer... ----------------</span></span>
<span id="cb28-18"><a href="#cb28-18" aria-hidden="true" tabindex="-1"></a><span class="co"># add a page break to start a new page</span></span>
<span id="cb28-19"><a href="#cb28-19" aria-hidden="true" tabindex="-1"></a>doc.add_page_break()</span>
<span id="cb28-20"><a href="#cb28-20" aria-hidden="true" tabindex="-1"></a><span class="co"># add a heading of level 2</span></span>
<span id="cb28-21"><a href="#cb28-21" aria-hidden="true" tabindex="-1"></a>doc.add_heading(<span class="st">'DISCLAIMER:'</span>, <span class="dv">2</span>)</span>
<span id="cb28-22"><a href="#cb28-22" aria-hidden="true" tabindex="-1"></a>doc_para <span class="op">=</span> doc.add_paragraph() </span>
<span id="cb28-23"><a href="#cb28-23" aria-hidden="true" tabindex="-1"></a>doc_para.add_run(<span class="st">'This document contains material generated by artificial intelligence technology. While efforts have been made to ensure accuracy, please be aware that AI-generated content may not always fully represent the intent or expertise of human-authored material and may contain errors or inaccuracies. An AI model might generate content that sounds plausible but that is either factually incorrect or unrelated to the given context. These unexpected outcomes, also called AI hallucinations, can stem from biases, lack of real-world understanding, or limitations in training data.'</span>).italic <span class="op">=</span> <span class="va">True</span></span>
<span id="cb28-24"><a href="#cb28-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-25"><a href="#cb28-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Save the document ---------------</span></span>
<span id="cb28-26"><a href="#cb28-26" aria-hidden="true" tabindex="-1"></a>doc.save(<span class="st">"generated/Evaluation_Brief_response_text_bert.docx"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
<section id="process-evaluation" class="level2">
<h2 class="anchored" data-anchor-id="process-evaluation">Process Evaluation</h2>
<p>We were able to get a first brief… still how can we assess how good is this report?</p>
<section id="build-an-alternate-brief" class="level3">
<h3 class="anchored" data-anchor-id="build-an-alternate-brief">Build an alternate “Brief”</h3>
<p>Let’s try to generate a second report with different settings. Let’s try first with a second embedding model… <a href="https://huggingface.co/models?pipeline_tag=feature-extraction&amp;sort=trending">Hugging face</a> has many options… and there is even a <a href="https://huggingface.co/spaces/mteb/leaderboard">leaderboard</a> to see how they compete… We will select here the embedding model <a href="https://huggingface.co/BAAI/bge-large-en-v1.5">bge-large-en-v1.5</a> from the Beijing Academy of Artificial Intelligence. It is small in size but efficient and it does not consume too much memory.</p>
<div class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain_community.embeddings <span class="im">import</span> HuggingFaceBgeEmbeddings</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>model_name <span class="op">=</span> <span class="st">"BAAI/bge-small-en"</span></span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>model_kwargs <span class="op">=</span> {<span class="st">"device"</span>: <span class="st">"cpu"</span>}</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>encode_kwargs <span class="op">=</span> {<span class="st">"normalize_embeddings"</span>: <span class="va">True</span>}</span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>embeddings_bge<span class="op">=</span> HuggingFaceBgeEmbeddings(</span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a>    model_name<span class="op">=</span>model_name, model_kwargs<span class="op">=</span>model_kwargs, encode_kwargs<span class="op">=</span>encode_kwargs</span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/edouard/.pyenv/versions/3.11.6/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html
  from .autonotebook import tqdm as notebook_tqdm</code></pre>
</div>
</div>
<p>We build the vector store using the new embedding…</p>
<div class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>vectorstore_recursivecharactertext_bge <span class="op">=</span> Chroma.from_documents(chunks_recursivecharactertext,</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>                                                   embeddings_bge,</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>                                               collection_name<span class="op">=</span> <span class="st">"recursivecharactertext_bge"</span>,</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>                                               persist_directory <span class="op">=</span> <span class="st">"persist"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
    - Avoid using `tokenizers` before the fork if possible
    - Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
    - Avoid using `tokenizers` before the fork if possible
    - Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)</code></pre>
</div>
</div>
<p>…create our retriever now using Maximum Marginal Relevance…</p>
<div class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>ragRetriever_mmr_recursivecharactertext_bge <span class="op">=</span> vectorstore_recursivecharactertext_bge.as_retriever(</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>            search_type<span class="op">=</span><span class="st">"mmr"</span></span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>and let’s use a different model for the LLM: <a href="https://cohere.com/blog/command-r">command-r)</a>, and specifically the quantized version: <a href="https://ollama.com/library/command-r:35b-v0.1-q4_K_M">command-r:35b-v0.1-q4_K_M</a>, an open-weight model designed to optimize RAG.</p>
<div class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain_community.chat_models <span class="im">import</span> ChatOllama</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>llm_ollama2 <span class="op">=</span> ChatOllama(</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>    model<span class="op">=</span><span class="st">"command-r:35b-v0.1-q4_K_M"</span>,  </span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a>    temperature<span class="op">=</span><span class="fl">0.2</span>, </span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a>    request_timeout<span class="op">=</span><span class="dv">500</span></span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>… and then get our summary with the second LLM!</p>
<div class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain.chains <span class="im">import</span> RetrievalQA</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>qa_chain <span class="op">=</span> RetrievalQA.from_chain_type(</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>        llm<span class="op">=</span>llm_ollama2,</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a>        retriever<span class="op">=</span>ragRetriever_mmr_recursivecharactertext_bge, </span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a>        chain_type<span class="op">=</span><span class="st">"stuff"</span>,</span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a>        return_source_documents<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a>response_mmr_recursivecharactertext_bge <span class="op">=</span> qa_chain(RAG_prompt)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now saving it in a word document!</p>
<div class="cell" data-execution_count="30">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> docx</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a document</span></span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a>doc <span class="op">=</span> docx.Document()</span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a><span class="co"># add a heading of level 0 (largest heading)</span></span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a>doc.add_heading(<span class="st">'Evaluation Brief'</span>, <span class="dv">0</span>) </span>
<span id="cb36-8"><a href="#cb36-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-9"><a href="#cb36-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Add another paragraph</span></span>
<span id="cb36-10"><a href="#cb36-10" aria-hidden="true" tabindex="-1"></a>p <span class="op">=</span> doc.add_paragraph()</span>
<span id="cb36-11"><a href="#cb36-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-12"><a href="#cb36-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Add a run with the summary and format it</span></span>
<span id="cb36-13"><a href="#cb36-13" aria-hidden="true" tabindex="-1"></a>run <span class="op">=</span> p.add_run(response_mmr_recursivecharactertext_bge[<span class="st">"result"</span>])</span>
<span id="cb36-14"><a href="#cb36-14" aria-hidden="true" tabindex="-1"></a>run.font.name <span class="op">=</span> <span class="st">'Arial'</span></span>
<span id="cb36-15"><a href="#cb36-15" aria-hidden="true" tabindex="-1"></a>run.font.size <span class="op">=</span> docx.shared.Pt(<span class="dv">12</span>)</span>
<span id="cb36-16"><a href="#cb36-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-17"><a href="#cb36-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-18"><a href="#cb36-18" aria-hidden="true" tabindex="-1"></a><span class="co">## Add  a disclaimer... ----------------</span></span>
<span id="cb36-19"><a href="#cb36-19" aria-hidden="true" tabindex="-1"></a><span class="co"># add a page break to start a new page</span></span>
<span id="cb36-20"><a href="#cb36-20" aria-hidden="true" tabindex="-1"></a>doc.add_page_break()</span>
<span id="cb36-21"><a href="#cb36-21" aria-hidden="true" tabindex="-1"></a><span class="co"># add a heading of level 2</span></span>
<span id="cb36-22"><a href="#cb36-22" aria-hidden="true" tabindex="-1"></a>doc.add_heading(<span class="st">'DISCLAIMER:'</span>, <span class="dv">2</span>)</span>
<span id="cb36-23"><a href="#cb36-23" aria-hidden="true" tabindex="-1"></a>doc_para <span class="op">=</span> doc.add_paragraph() </span>
<span id="cb36-24"><a href="#cb36-24" aria-hidden="true" tabindex="-1"></a>doc_para.add_run(<span class="st">'This document contains material generated by artificial intelligence technology. While efforts have been made to ensure accuracy, please be aware that AI-generated content may not always fully represent the intent or expertise of human-authored material and may contain errors or inaccuracies. An AI model might generate content that sounds plausible but that is either factually incorrect or unrelated to the given context. These unexpected outcomes, also called AI hallucinations, can stem from biases, lack of real-world understanding, or limitations in training data.'</span>).italic <span class="op">=</span> <span class="va">True</span></span>
<span id="cb36-25"><a href="#cb36-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-26"><a href="#cb36-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Save the document ---------------</span></span>
<span id="cb36-27"><a href="#cb36-27" aria-hidden="true" tabindex="-1"></a>doc.save(<span class="st">"generated/Evaluation_Brief_response_mmr_recursivecharactertext_bge.docx"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Et voila! When reading the two reports, we can see significant differences… which is OK as it would be if it was a human doing it.. Though, it is likely that one report is better than the other. Now let’s <strong>evaluate</strong> the quality of the summarization to objectively find out about this!</p>
</section>
<section id="building-the-evaluation-dataset" class="level3">
<h3 class="anchored" data-anchor-id="building-the-evaluation-dataset">Building the evaluation dataset</h3>
<p>To do the evaluation, first we need to build an large-enough evaluation dataset so that the evaluation is based on multiple output. One approach is to extract from the report both:</p>
<ul>
<li><p>all <strong>findings and evidence</strong>, i.e.&nbsp;what can be learnt from the specific context of this evaluation study, what are the root causes for the finding in this context and what are the main risks and difficulties in this context.</p></li>
<li><p>all <strong>recommendations</strong>, flagging clearly if the recommendations relate to practices that should be either discontinued on one side or on the other side to practices that should be scaled up.</p></li>
</ul>
<p>To provide more perspectives for the extraction, the report can be reviewed from the angle of each of the potential 26 different type of experts that may look at UNHCR programme:</p>
<ul>
<li><p><strong>4 experts for Strategic Impact</strong> Peer Review: i.e., finding or recommendations that require a change in existing policy and regulations in relation within the specific impact area:</p>
<ol type="1">
<li>Attaining favorable protection environments</li>
<li>Realizing rights in safe environments</li>
<li>Empowering communities and achieving gender equality</li>
<li>Securing durable solutions</li>
</ol></li>
<li><p><strong>17 experts for Operational Outcome</strong> Peer Review: i.e., finding or recommendations that require a change that needs to be implemented in the field as an adaptation or change of current activities in relation within the specific outcome area:</p>
<ol type="1">
<li>Access to territory registration and documentation</li>
<li>Status determination</li>
<li>Protection policy and law</li>
<li>Gender-based violence</li>
<li>Child protection</li>
<li>Safety and access to justice</li>
<li>Community engagement and women’s empowerment</li>
<li>Well-being and basic needs</li>
<li>Sustainable housing and settlements</li>
<li>Healthy lives</li>
<li>Education</li>
<li>Clean water sanitation and hygiene</li>
<li>Self-reliance, Economic inclusion, and livelihoods</li>
<li>Voluntary repatriation and sustainable reintegration</li>
<li>Resettlement and complementary pathways</li>
<li>Local integration and other local solutions</li>
</ol></li>
<li><p><strong>5 experts on Organizational Enabler</strong> Peer Review: i.e., finding or recommendations that require changes in management practices, technical approach, business processes, staffing allocation or capacity building in relation with:</p>
<ol type="1">
<li>Systems and processes</li>
<li>Operational support and supply chain</li>
<li>People and culture</li>
<li>External engagement and resource mobilization</li>
<li>Leadership and governance</li>
</ol></li>
</ul>
<div class="cell" data-execution_count="31">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="co"># create the QA chain</span></span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain.chains <span class="im">import</span> RetrievalQA</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a>qa_chain <span class="op">=</span> RetrievalQA.from_chain_type(</span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a>        llm<span class="op">=</span>llm_ollama,</span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a>        retriever<span class="op">=</span>ragRetriever_mmr_recursivecharactertext_bge, </span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a>        return_source_documents<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a><span class="co"># testing it out</span></span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a>question <span class="op">=</span> <span class="st">"Provide a list of all organisational recommendations within the report"</span></span>
<span id="cb37-10"><a href="#cb37-10" aria-hidden="true" tabindex="-1"></a><span class="co">#result = qa_chain({"query": question})</span></span>
<span id="cb37-11"><a href="#cb37-11" aria-hidden="true" tabindex="-1"></a><span class="co">#result["result"]</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="metrics-measurement" class="level3">
<h3 class="anchored" data-anchor-id="metrics-measurement">Metrics Measurement</h3>
<p>Getting the RAG pipeline’s performance to a satisfying state is not straightforward. <a href="https://docs.ragas.io/en/stable/">RAGAS (Retrieval Augmented Generation Assessment)</a> is a framework for reference-free evaluation of RAG pipelines. <em>“Reference-free”</em> evaluation means that instead of having to rely on human-annotated ground truth labels in the evaluation dataset, RAGAs leverages LLMs under the hood to conduct the <a href="https://docs.ragas.io/en/stable/howtos/integrations/langchain.html">evaluations</a>.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>There are several criteria used to <strong>evaluate RAG applications</strong>:</p>
<ol type="1">
<li>Context-based for the <strong>Retriever</strong>: :</li>
</ol>
<ul>
<li><p><a href="https://docs.ragas.io/en/stable/concepts/metrics/context_recall.html"><strong>Context recall</strong></a>: Measures whether the context contains the correct information, compared to a provided ground truth, in order to produce an answer.</p></li>
<li><p><a href="https://docs.ragas.io/en/stable/concepts/metrics/context_precision.html"><strong>Context Precision</strong></a> (also called Grounding): Measures whether items present in the contexts are ranked higher or not.</p></li>
</ul>
<ol start="2" type="1">
<li>Output-based for the <strong>Generator</strong> (LLM):</li>
</ol>
<ul>
<li><p><a href="https://docs.ragas.io/en/stable/concepts/metrics/faithfulness.html"><strong>Faithfulness</strong></a> (also called Correctness or Factuality): Measures whether the LLM outputs are based on the provided ground truth.</p></li>
<li><p><a href="https://docs.ragas.io/en/stable/concepts/metrics/answer_relevance.html"><strong>Answer relevancy</strong></a>: Measures how directly the answer addresses the question.</p></li>
</ul>
</div>
</div>
<p>We can use a <a href="https://docs.ragas.io/en/stable/howtos/customisations/ragas_custom_model.html#">dedicated model</a> as a critic of the first one</p>
<div class="cell" data-execution_count="32">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="co"># from langchain_community.llms import VLLM</span></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a><span class="co"># critic_llm = VLLM(</span></span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a><span class="co">#     model="explodinggradients/Ragas-critic-llm-Qwen1.5-GPTQ",</span></span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a><span class="co">#     trust_remote_code=True,  # mandatory for hf models</span></span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a><span class="co">#     max_new_tokens=512,</span></span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a><span class="co">#     top_k=10,</span></span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a><span class="co">#     top_p=0.95,</span></span>
<span id="cb38-9"><a href="#cb38-9" aria-hidden="true" tabindex="-1"></a><span class="co">#     temperature=0.0,)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="33">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="co"># from ragas import evaluate</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="34">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="co"># from ragas.metrics import context_precision, answer_relevancy, faithfulness</span></span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a><span class="co"># from ragas import evaluate</span></span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a><span class="co"># raga_result = evaluate(</span></span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a><span class="co">#     dataset=result,</span></span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a><span class="co">#     llm=critic_llm,</span></span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a><span class="co">#     metrics=[context_precision, faithfulness, answer_relevancy],</span></span>
<span id="cb40-8"><a href="#cb40-8" aria-hidden="true" tabindex="-1"></a><span class="co"># )</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
<section id="ai-deployment" class="level2">
<h2 class="anchored" data-anchor-id="ai-deployment">AI Deployment</h2>
<section id="buy-or-build" class="level3">
<h3 class="anchored" data-anchor-id="buy-or-build">Buy or Build?</h3>
<p>As presented in <a href="https://www.gartner.com/en/information-technology/topics/ai-readiness">Gartner AI readiness framework</a>, there are potential graduated steps in terms of deployment: consume, embed, extend and build, and for each strategic decisions between outsourced/internalized are required.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="https://www.gartner.com/en/information-technology/topics/ai-readiness"><img src="GL0vYd_WcAAqUDZ.png" class="img-fluid figure-img"></a></p>
<figcaption class="figure-caption">From Gartner: https://www.gartner.com/en/information-technology/topics/ai-readiness</figcaption>
</figure>
</div>
<p>Using off-the-shelves solutions, such as Commercial Copilot, in a “consume or embed” mode comes with inherent limitations:</p>
<ul>
<li>to incorporate organization specific Knowledge in a systematic way;</li>
<li>to continuously update the knowledge base with any latest content;</li>
<li>to prevent what is called “Hallucinations”, in other words the risk of generating incorrect or misleading information, that would not be context-aware.</li>
</ul>
<p>This paper actually presented a recipe to extend existing foundation model, using the first step: Data Retrival and Prompt engineering. We highlighted the importance of the configuration to ensure the <strong>reliability of the system</strong> and therefore the relevance of managing directly such process.</p>
<p>The next step, Fine Tuning comes first with the additional requirement to build AI ready and validated data.</p>
</section>
<section id="ai-ready-data-human-review" class="level3">
<h3 class="anchored" data-anchor-id="ai-ready-data-human-review">AI ready data &amp; Human Review</h3>
<p>Building common knowledge on “data retrieval scripts” could be the first achievable target. This would imply to tune a RAG extraction for each evaluation report and build an evaluation dataset for each of them.</p>
<p>Human Review is key to maintaining quality, minimizing the risk of hallucination and enforcing alignment. It can be performed both before and after fine-tuning. Human labelling is performed to verify that the response is relevant, generic or out-of-context. A platform like <a href="https://labelstud.io/">labelStudioo</a> can be used to implement such human review. The “Context/Question/Response” shall be reviewed and assessed as “Relevant” / “Generic” / “Out-of-scope”.</p>
<p>After the peer review is sent to observation, operation feedback on the review can also be collected and use at a later stage to further fine tune the model</p>
</section>
<section id="fine-tuning" class="level3">
<h3 class="anchored" data-anchor-id="fine-tuning">Fine-Tuning</h3>
<p>Using the labeled dataset, generated from the prompt, and then labeled, the next step will be to select any Open “foundational” LLM from HuggingFace and fine tune it. In line with UN statement to promote open source in general and <a href="https://www.un.org/techenvoy/content/digital-public-goods">“open artificial intelligence models”</a>, the resulting fine-tuned model could also be published on <a href="https://huggingface.co/">huggingface</a>.</p>
<p>A fine tune model could help front-loading many more contexts that a simple foundation model:</p>
<ul>
<li><p><strong>Situation</strong> – The fine-tune model would be relevant and specific in relation with Operation profile, Area of focus between one of the strategic impact, operational outcome, or organizational topics</p></li>
<li><p><strong>Task</strong> - The fine-tune model could be triggered at a specific stage of the operation management cycle for Peer Review Purpose – at any stage of the Plan/Get/Show.</p></li>
<li><p><strong>Activity</strong> – Based on the combination of situation and task, the fine-tune model would help re-injecting previously found evidence and/or recalling recommendations</p></li>
<li><p><strong>Results</strong> – The fine-tune model output would be systematically saved in order to be re-assessed by humans to fine-tune it further from this feedback and improve over time (also called reinforcement learning.)</p></li>
</ul>
</section>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>Leveraging the potential of AI for evaluation implies significant investement. Tuning RAG extraction pipeline and building evaluation dataset for each evaluation report implies to set up a dedicated team and infrastructure.</p>
<p>Given the size of linked investment, pooling expertise (sharing scripts) and accessing capacity (server infrastructure) around this objective and across the UN system could make sense.</p>
</section>

</main>
<!-- /main column -->
<div class="py-4 column-screen page-columns page-full" style="background-color: #333333">
  <div class="column-body">
    <a href="https://www.unhcr.org/" target="_blank" rel="noopener noreferrer">
      <img src="data:image/svg+xml;base64,<?xml version="1.0" encoding="utf-8"?>
<!-- Generator: Adobe Illustrator 25.2.0, SVG Export Plug-In . SVG Version: 6.00 Build 0)  -->
<svg version="1.1" id="Layer_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
	 viewBox="0 0 225.9 54.3" style="enable-background:new 0 0 225.9 54.3;" xml:space="preserve">
<style type="text/css">
	.st0{fill:#FFFFFF;}
</style>
<path class="st0" d="M33,36.7c0.6,0,0.6-0.4,0.6-1v-3.3c0-0.7-0.1-0.9,0.3-0.9c1.4,0,1.7-0.1,1.7-1.3V17.9c0-3.3-2.4-2.8-3-4
	c-1-1.6,1.8-1.6,0.8-5.2c-0.3-0.9-1.2-1.4-2.1-1.3c-0.9-0.1-1.8,0.4-2.1,1.3c-1,3.6,1.7,3.6,0.8,5.2c-0.7,1.2-3,0.7-3,4v12.3
	c0,1.2,0.4,1.3,1.7,1.3c0.4,0,0.3,0.2,0.3,0.9v3.3c0,0.7-0.1,1,0.6,1H33"/>
<path class="st0" d="M22.3,10.1c-1.2,1.3-3.1,4.3-1.9,6.8c2.5,1,2.3-8,5.5-7.9c1.6,1.4-0.5,5.7-1.1,7.5c-0.8,2.3-1.4,7.1-2.9,9.5
	c-1.2,2-0.3,8.1-0.7,10.2c-1,1-3.9,0.3-5.1,0.1c-0.1-2.7-0.3-5.5-0.7-8.2c0-0.8-0.9-12.7-0.2-14.1c1.4-3,8.8-8.7,9.8-9.8
	S29,0,30.3,0c0.9,0.6,0.4,2,0.2,2.5C29.3,5.5,24,8.5,22.3,10.1"/>
<path class="st0" d="M40.4,10.1c1.2,1.3,3.1,4.3,1.9,6.8c-2.6,1-2.4-8-5.5-7.9c-1.5,1.4,0.5,5.7,1.1,7.5c0.8,2.3,1.4,7.1,2.9,9.5
	c1.2,2,0.3,8.1,0.7,10.2c1.1,1,3.9,0.3,5.1,0.1c0.1-2.7,0.3-5.5,0.7-8.2c0.1-0.8,0.9-12.7,0.2-14.1c-1.4-3-8.8-8.7-9.8-9.8
	S33.6,0,32.4,0c-0.9,0.6-0.3,2-0.2,2.5C33.5,5.5,38.7,8.5,40.4,10.1"/>
<path class="st0" d="M11.5,6.1c-0.7,0.6-2.1,1.1-3.2,2.4C7.9,7.8,8.9,6,10.1,4.9c1-0.8,2.1-1.5,3.2-2.1C13.7,3.7,12.3,5.1,11.5,6.1"
	/>
<path class="st0" d="M9.4,11c-1.1,1-2.3,1.5-3.9,3.4C5,12.5,4.9,10.6,5.3,8.7c0.6-1.8,1.5-3.8,3-4.4C7.8,5.7,7.5,7.1,7.4,8.6
	c-0.7,2.6-1,2.7-0.9,3c0.2,0,1-1.4,2.1-2.4c1.2-1.2,2.8-1.5,3.8-2.3C11.6,8.4,10.6,9.8,9.4,11"/>
<path class="st0" d="M3.9,21.8c-1.2-2.1-1.8-4.6-1.8-7c0.1-1.6,0.9-5.3,2-5.9c-0.3,3.4,0.6,3.7,0.2,6.4c0,0.1-0.4,3-0.4,3.2
	c0.5-0.1,0-2.6,5.4-6.4c-1.2,2-0.6,2.6-2.7,5.3C5.4,18.6,4.4,20.1,3.9,21.8"/>
<path class="st0" d="M6.1,24.3c-0.7,0.9-1.1,2-1.2,3.2C2.2,26-0.9,19.8,0.2,16.7c0.7,2.3,1.7,2.9,2.4,4.8c1.2,2.9,1,3.8,1.8,4.5
	c-0.1-1.6,0.2-3.2,0.9-4.6c0.6-1.1,1.2-2.1,1.9-3.1C7.7,20.4,7.3,22.1,6.1,24.3"/>
<path class="st0" d="M8.5,29.6c-0.1,1.7-0.3,3.5-0.6,5.2c-4.6-1.5-7.1-6.8-7.1-9.4c1.4,3.2,3.5,3.2,6.2,7.7c0.2-1.7-0.5-0.4-0.6-3.7
	c0.1-3.4,0.8-3.5,0.9-5.6C8.2,24.7,8.5,28.5,8.5,29.6"/>
<path class="st0" d="M12.3,36.4c0.4,1.8,0.5,3.8,0.8,5.3c-2.7-1-3.3-0.2-6.5-2.2c-1.4-0.8-4-4.1-3.9-6.4c3.1,3.5,3.7,3.1,5.2,4.4
	c1.4,1.1,2.5,2.8,3.6,2.6c0.1-0.9-2.3-3-2-8.8C10.8,32.8,11.7,34.5,12.3,36.4"/>
<path class="st0" d="M17.6,40.8c0.8,1.2,0.6,1.7,2.7,4.1c-1.8,0.6-3.6,0.9-5.5,1.1c-1.3,0-6-1.2-7.6-4.4c2.7,1.4,2.7,1.1,6.3,1.9
	c2.6,0.6,4.4,1.4,5.1,1.3c-0.1-0.3-2.1-1.2-3.5-2.9s-1-3.9-2.3-5.4C13.7,36.1,16.9,39.9,17.6,40.8"/>
<path class="st0" d="M51,6.1c0.6,0.6,2.2,1.1,3.1,2.4c0.4-0.7-0.6-2.5-1.8-3.6c-1-0.8-2-1.5-3.2-2.1C48.7,3.7,50.1,5.1,51,6.1"/>
<path class="st0" d="M53.1,11c1.1,1,2.3,1.5,3.9,3.4c0.5-1.9,0.6-3.8,0.2-5.7c-0.5-1.8-1.5-3.8-3-4.4c0.5,1.4,0.8,2.8,0.9,4.3
	c0.7,2.6,1,2.7,0.9,3c-0.2,0-1-1.4-2.1-2.4c-1.2-1.2-2.7-1.5-3.8-2.3C50.9,8.4,51.9,9.8,53.1,11"/>
<path class="st0" d="M58.5,21.8c1.2-2.1,1.8-4.5,1.8-7c-0.1-1.6-0.9-5.3-2-5.9c0.3,3.4-0.6,3.7-0.2,6.4c0,0.1,0.3,3,0.3,3.2
	c-0.4-0.1,0-2.6-5.3-6.4c1.1,2,0.6,2.6,2.7,5.3C57.1,18.6,58,20.1,58.5,21.8"/>
<path class="st0" d="M56.4,24.3c0.6,1,1,2.1,1.2,3.2c2.7-1.6,5.8-7.8,4.6-10.8c-0.7,2.3-1.7,2.9-2.3,4.8c-1.3,2.9-1.1,3.8-1.8,4.5
	c0-1.6-0.3-3.1-0.9-4.6c-0.5-1.1-1.2-2.1-1.9-3.1C54.8,20.4,55.2,22.5,56.4,24.3"/>
<path class="st0" d="M54,29.6c0.1,1.8,0.3,3.5,0.7,5.2c4.6-1.5,7.1-6.8,7.1-9.4c-1.5,3.2-3.5,3.2-6.2,7.7c-0.2-1.7,0.5-0.4,0.5-3.7
	s-0.8-3.5-0.9-5.6C54.3,24.7,54,28.5,54,29.6"/>
<path class="st0" d="M50.1,36.4c-0.4,1.8-0.5,3.8-0.7,5.3c2.6-1,3.3-0.2,6.4-2.2c1.4-0.8,4.1-4.1,3.9-6.4c-3.1,3.5-3.7,3.1-5.2,4.4
	c-1.4,1.1-2.6,2.8-3.6,2.6c-0.1-0.9,2.3-3,2-8.8C51.7,32.8,50.7,34.5,50.1,36.4"/>
<path class="st0" d="M44.9,40.8c-0.7,1.5-1.6,2.9-2.7,4.1c1.8,0.6,3.6,0.9,5.5,1.1c1.3,0,6-1.2,7.5-4.4c-2.7,1.4-2.7,1.1-6.3,1.9
	c-2.6,0.6-4.4,1.4-5.1,1.3c0.2-0.3,2.2-1.2,3.5-2.9s1-3.9,2.3-5.4C48.7,36.1,45.6,39.9,44.9,40.8"/>
<path class="st0" d="M24.6,51.8l-0.8-0.4c3.4-3.8,8.4-5.8,13.5-5.6c8.5,0.5,7.9,2.5,12.5,2.1c0.5,0-0.4,0.6-0.4,0.6
	c-3.3,1-6.8,1-10-0.2C33.9,46.5,30.3,45.4,24.6,51.8"/>
<path class="st0" d="M38,51.8l0.8-0.4c-3.4-3.8-8.3-5.8-13.4-5.6c-8.5,0.5-7.9,2.5-12.5,2.1c-0.5,0,0.4,0.6,0.4,0.6
	c3.3,1,6.8,1,10-0.2C28.8,46.5,32.3,45.4,38,51.8"/>
<path class="st0" d="M98.3,25.5c0,8.1-4.4,12.1-13.4,12.1s-13.4-3.9-13.4-12.1v-18h9v16c0,3,0,6.8,4.4,6.8s4.3-3.8,4.3-6.8v-16h9.1
	V25.5"/>
<polygon class="st0" points="103.7,7.4 113,7.4 121.6,23.1 121.6,23.1 121.6,7.4 130.2,7.4 130.2,36.8 121.4,36.8 112.4,20.8 
	112.3,20.8 112.3,36.8 103.7,36.8 "/>
<polygon class="st0" points="135.8,7.4 144.8,7.4 144.8,17.6 153.3,17.6 153.3,7.4 162.3,7.4 162.3,36.8 153.3,36.8 153.3,25.2 
	144.8,25.2 144.8,36.8 135.8,36.8 "/>
<path class="st0" d="M185.5,18.4c-0.2-2.4-2.3-4.3-4.7-4.3c-4.2,0-5.6,4.1-5.6,8.1s1.4,8.1,5.6,8.1c3,0,4.2-2.1,4.8-4.9h8.9
	c0,5.9-4.8,12.2-13.4,12.2c-9.5,0-14.9-6.7-14.9-15.4c0-9.3,5.8-15.4,14.9-15.4c8.1,0,12.5,4.3,13.3,11.6L185.5,18.4"/>
<path class="st0" d="M207.3,14.4h4.2c3.5,0,4.5,1.1,4.5,2.9c0,2.6-2.3,2.9-4,2.9h-4.7V14.4z M198.2,36.8h9.1V26.6h4.8
	c3.6,0,3.8,2.9,4.1,5.7c0.1,1.5,0.3,3,0.7,4.5h9c-0.8-1.4-0.9-4.9-1-6.3c-0.3-3.7-1.9-6.4-4.3-7.3c3-1.1,4.4-4.3,4.4-7.4
	c0-5.6-4.4-8.4-9.6-8.4h-17.2V36.8"/>
<polygon class="st0" points="74.5,43.6 71.5,43.6 71.5,41.7 79.6,41.7 79.6,43.6 76.6,43.6 76.6,51.6 74.5,51.6 "/>
<path class="st0" d="M80.3,41.7h2v3.7l0,0c0.4-0.7,1.2-1.2,2.1-1.2c2.1,0,2.6,1.2,2.6,2.9v4.4h-2v-4c0-1.2-0.3-1.8-1.3-1.8
	s-1.5,0.6-1.5,2v3.7h-2L80.3,41.7"/>
<path class="st0" d="M89.7,48.5c0.1,1.2,0.7,1.8,1.8,1.8c0.6,0,1.2-0.3,1.5-0.9h1.7c-0.4,1.5-1.8,2.5-3.3,2.4
	c-1.9,0.1-3.5-1.4-3.6-3.3v-0.4c-0.1-2,1.4-3.7,3.4-3.8c0,0,0,0,0,0h0.3c2.4,0,3.6,2,3.5,4.2H89.7z M92.9,47.3
	c-0.2-1-0.6-1.5-1.6-1.5c-0.8,0-1.5,0.6-1.6,1.4v0.1H92.9"/>
<path class="st0" d="M107.6,47.9c0,2.7-1.6,4-4.2,4s-4.2-1.3-4.2-4v-6.1h2.2v6.1c0,1.1,0.3,2.1,2,2.1c1.5,0,2-0.7,2-2.1v-6.1h2.2
	V47.9"/>
<polygon class="st0" points="109,41.7 111.2,41.7 115.3,48.3 115.3,48.3 115.3,41.7 117.4,41.7 117.4,51.6 115.2,51.6 111.1,45 
	111.1,45 111.1,51.6 109,51.6 "/>
<path class="st0" d="M124.2,43.4h2.4c1,0,1.5,0.4,1.5,1.4s-0.5,1.4-1.5,1.4h-2.4L124.2,43.4z M122.1,51.6h2.2v-3.8h2.2
	c1.1,0,1.5,0.5,1.6,1.5c0,0.8,0.1,1.6,0.4,2.4h2.2c-0.3-0.7-0.4-1.5-0.4-2.3c-0.1-1-0.4-2-1.4-2.3l0,0c1-0.4,1.7-1.4,1.6-2.5
	c0-1.5-1.2-2.7-2.7-2.7c0,0,0,0,0,0h-5.5L122.1,51.6"/>
<path class="st0" d="M133.2,47.3c0-0.8,0.7-1.5,1.5-1.5h0.1c0.9,0,1.4,0.5,1.6,1.5H133.2z M138.3,48.5c0.1-2.2-1-4.2-3.5-4.2
	c-1.9-0.1-3.5,1.5-3.6,3.4c0,0,0,0.1,0,0.1V48c-0.2,1.9,1.2,3.5,3.1,3.7c0,0,0.1,0,0.1,0h0.4c1.5,0.1,2.9-0.9,3.3-2.4h-1.7
	c-0.3,0.6-0.9,1-1.5,0.9c-1.1,0-1.7-0.6-1.8-1.8L138.3,48.5"/>
<path class="st0" d="M139.6,45.8h-1.2v-1.3h1.2V44c-0.1-1.1,0.8-2.1,1.9-2.2c0,0,0.1,0,0.1,0h0.4c0.3,0,0.7,0,1,0.1v1.5h-0.7
	c-0.5,0-0.7,0.2-0.7,0.8v0.4h1.4v1.3h-1.4v5.8h-2V45.8"/>
<path class="st0" d="M150.2,51.6h-1.9v-1l0,0c-0.5,0.7-1.3,1.2-2.2,1.2c-2.1,0-2.6-1.2-2.6-2.9v-4.4h2v4c0,1.2,0.4,1.8,1.3,1.8
	c1.1,0,1.5-0.6,1.5-2v-3.8h2v7.1"/>
<path class="st0" d="M154.7,49.9c-1.2,0-1.6-1.1-1.6-2.1s0.5-2,1.6-2c1.3,0,1.7,1,1.7,2.2c0.2,0.9-0.5,1.8-1.4,2c0,0-0.1,0-0.1,0
	C154.8,50,154.8,50,154.7,49.9 M158.3,44.5h-1.9v1l0,0c-0.4-0.8-1.2-1.2-2.1-1.1c-1.8,0.1-3.2,1.5-3.1,3.3c0,0.1,0,0.1,0,0.2
	c0,1.8,0.9,3.6,3,3.6c0.8,0,1.6-0.4,2.1-1.1l0,0v0.9c0,1-0.5,1.8-1.6,1.8c-0.7,0.1-1.3-0.3-1.5-1h-1.9c0.1,1.6,1.7,2.3,3.1,2.3
	c3.3,0,3.7-2,3.7-3.2L158.3,44.5"/>
<path class="st0" d="M161.2,47.3c0-0.8,0.7-1.5,1.5-1.5h0.1c1,0,1.4,0.5,1.6,1.5H161.2z M166.3,48.5c0.1-2.2-1-4.2-3.5-4.2
	c-1.9-0.1-3.5,1.5-3.6,3.4c0,0,0,0.1,0,0.1V48c-0.2,1.9,1.2,3.5,3.1,3.7c0,0,0.1,0,0.1,0h0.4c1.5,0.1,2.9-0.9,3.3-2.4h-1.7
	c-0.3,0.6-0.9,1-1.5,0.9c-1.1,0-1.7-0.6-1.8-1.8L166.3,48.5"/>
<path class="st0" d="M168.9,47.3c0-0.8,0.7-1.5,1.5-1.5c0,0,0.1,0,0.1,0h0.1c0.9,0,1.4,0.5,1.6,1.5H168.9z M174,48.5
	c0.1-2.2-1-4.2-3.5-4.2c-1.9-0.1-3.5,1.5-3.6,3.4c0,0,0,0.1,0,0.1V48c-0.2,1.9,1.2,3.5,3.1,3.7c0,0,0.1,0,0.1,0h0.4
	c1.5,0.1,2.9-0.9,3.3-2.4h-1.7c-0.3,0.6-0.9,1-1.6,0.9c-1.1,0-1.7-0.6-1.8-1.8L174,48.5"/>
<path class="st0" d="M183,44.2L183,44.2l1.2,3.6h-2.6L183,44.2z M178.2,51.6h2.2l0.8-2.2h3.7l0.7,2.2h2.3l-3.7-9.8H182L178.2,51.6z"
	/>
<path class="st0" d="M191.5,49.9c-1.2,0-1.6-1.1-1.6-2.1s0.5-2,1.6-2c1.3,0,1.7,1,1.7,2.2c0.1,1-0.5,1.8-1.5,2
	C191.6,50,191.5,50,191.5,49.9 M195,44.5h-1.9v1l0,0c-0.4-0.8-1.2-1.2-2.1-1.1c-1.8,0.1-3.2,1.5-3.1,3.3c0,0.1,0,0.1,0,0.2
	c0,1.8,0.9,3.6,3.1,3.6c0.8,0,1.6-0.4,2.1-1.1l0,0v0.9c0,1-0.5,1.8-1.6,1.8c-0.7,0.1-1.3-0.3-1.5-1h-1.9c0.1,1.6,1.7,2.3,3.1,2.3
	c3.3,0,3.7-2,3.7-3.2L195,44.5"/>
<path class="st0" d="M197.9,47.3c0-0.8,0.7-1.5,1.5-1.5c0,0,0.1,0,0.1,0h0.1c0.9,0,1.4,0.5,1.6,1.5H197.9z M203.1,48.5
	c0.1-2.2-1-4.2-3.5-4.2c-2,0-3.6,1.5-3.6,3.5V48c-0.2,1.9,1.2,3.5,3.1,3.7c0,0,0.1,0,0.1,0h0.4c1.5,0.1,2.9-0.9,3.3-2.4h-1.7
	c-0.3,0.6-0.9,1-1.6,0.9c-1.1,0-1.7-0.6-1.8-1.8L203.1,48.5"/>
<path class="st0" d="M203.9,44.5h1.9v1h0.1c0.5-0.7,1.3-1.2,2.2-1.2c2.1,0,2.6,1.2,2.6,2.9v4.4h-2v-4c0-1.2-0.3-1.8-1.3-1.8
	s-1.5,0.6-1.5,2v3.7h-2V44.5"/>
<path class="st0" d="M216.6,47c-0.1-0.7-0.7-1.2-1.4-1.2l0,0c-1.3,0-1.7,1.3-1.7,2.3s0.4,2.2,1.6,2.2c0.8,0,1.5-0.6,1.6-1.4h1.9
	c-0.1,1.7-1.5,3-3.2,2.9c-0.1,0-0.1,0-0.2,0l0,0c-1.9,0.1-3.5-1.4-3.6-3.3v-0.3c-0.2-1.9,1.1-3.6,3-3.8c0.1,0,0.1,0,0.2,0h0.5
	c1.7-0.2,3.2,1,3.4,2.7L216.6,47"/>
<path class="st0" d="M223,52.5c-0.3,1.1-1.4,1.8-2.5,1.6c-0.4,0-0.8,0-1.2-0.1v-1.6c0.4,0,0.8,0.1,1.1,0.1c0.5-0.1,0.8-0.6,0.8-1.1
	c0-0.1,0-0.2-0.1-0.3l-2.5-6.7h2.1l1.6,4.9l0,0l1.6-4.9h2L223,52.5"/>
</svg>
" alt="UNHCR Logo" class="img-fluid" style="max-height: 2.5rem">
    </a>
  </div>
</div>
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



<script src="index_files/libs/quarto-html/zenscroll-min.js"></script>
</body></html>